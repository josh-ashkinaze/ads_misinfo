{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b553e1ae",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a38bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "random.seed(416)\n",
    "np.random.seed(416)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b487aeba",
   "metadata": {},
   "source": [
    "# Power Analysis\n",
    "\n",
    "## Treatment Effect\n",
    "We estimate a treatment effect from a laboratory study and then \"discount\" this effect, informed by how other misinformation effects decayed in the field vs the lab. \n",
    "\n",
    "- A laboratory experiment (Kaiser et al (2022)) asked users to imagine that somebody the participant followed posted misinformation. Then the study asked participant's to rate their intentions to unfollow that individual on a scale of 1-6, with 1 being unfollowing \"does not at all apply\" and 6 being \"does fully apply\". Summing the percentage of respondents who answered 4-6 is a rough measure of the percentage of respondent's who would be more likely than not to unfollow. That sum is ~19%.\n",
    "\n",
    "- One study (Lin et al 2024) compared the effect size of accuracy nudges in the lab to the effect size of accurarcy nudges when used in a digital ad experiment similar to ours. We use this ratio to inform how much to discount Kaiser et al. (2022). From page 11, we use the lower bound of the ad efficacy (2.6%) and the upper bound of the lab estimate (10%) to arrive at a base discount factor of (1 - 2.6/10) 74%. Doing so would yield 26% of 19%  = 5%. So we sample treatment unfollowing proportions centered at 5% (which is the base case)\n",
    "\n",
    "## Control Rate\n",
    "- Ashkinaze et al (2024) looked at the unfollowing rate of health misinformation spreaders and found it was 0.52% per month (95% CI = [0.46%, 0.58%]) so we take the upper bound of this CI as the monthly rate\n",
    "\n",
    "- We then assume the effective control unfollowing rate would be monthly_rate / months = (monthly_rate / (n_days/30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f4d629-0765-4648-8e22-6f62daa2de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_task(control_prop, treatment_prop, n_days, N, treat_eligible, n_simulations, df):\n",
    "    adj_control_prop = control_prop * (n_days / 30)\n",
    "    power = estimate_power(df=df, N=N, \n",
    "                           control_prop=adj_control_prop, \n",
    "                           treatment_prop=treatment_prop, \n",
    "                           treat_eligible=treat_eligible, \n",
    "                           n_simulations=n_simulations, alpha=0.05)\n",
    "    return {'control_prop': control_prop, 'treatment_prop': treatment_prop, 'n_days': n_days, 'N': N, 'power_itt': power['itt_power'], 'power_cace':power['cace_power']}\n",
    "\n",
    "\n",
    "def run_power_analysis(params, df):\n",
    "    tasks = [(control_prop, treatment_prop, n_days, N, params['treat_eligible'][0], params['n_simulations'], df)\n",
    "             for control_prop in params['control_prop']\n",
    "             for treatment_prop in params['treatment_prop']\n",
    "             for n_days in params['n_days']\n",
    "             for N in params['N_values']]\n",
    "    \n",
    "    results = Parallel(n_jobs=-1)(delayed(process_task)(*task) for task in tqdm(tasks, desc='Running simulations'))\n",
    "    # results = [process_task(*task) for task in tasks]\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "\n",
    "def estimate_power(df, N, control_prop, treatment_prop, treat_eligible, alpha=0.05, n_simulations=100):\n",
    "    df_sample = df.sample(N, replace=False, random_state = np.random.randint(0,10000))\n",
    "    N_control = df_sample[df_sample['treated'] == 0].shape[0]\n",
    "    N_treatment = df_sample[df_sample['treated'] == 1].shape[0]\n",
    "    sig_itt = 0\n",
    "    sig_cace = 0\n",
    "    for i in range(n_simulations):\n",
    "        res_dict = difference_in_proportions_test(N_control, N_treatment, treat_eligible,  control_prop, treatment_prop, alpha)\n",
    "        itt_res, cace_res = res_dict['itt'], res_dict['cace']\n",
    "        if itt_res:\n",
    "            sig_itt +=1\n",
    "        if cace_res:\n",
    "            sig_cace +=1\n",
    "\n",
    "    power = {'itt_power':sig_itt/n_simulations, \"cace_power\":sig_cace/n_simulations}\n",
    "    return power\n",
    "\n",
    "def difference_in_proportions_test(N_control, N_treatment, treat_eligible, control_prop, treatment_prop, alpha=0.05):\n",
    "\n",
    "    # Only `treat_eligible' prop complies \n",
    "    n_treatment_compliers = int(N_treatment*treat_eligible)\n",
    "    n_treatment_noncompliers = N_treatment - n_treatment_compliers\n",
    "    \n",
    "    # Let us assume noncompliers had same unfollowing rate as control \n",
    "    control_outcomes = np.random.binomial(1, control_prop, size=N_control)\n",
    "    treatment_complier_outcomes = np.random.binomial(1, treatment_prop, size=n_treatment_compliers) # CACE\n",
    "    treatment_noncomplier_outcomes = np.random.binomial(1, control_prop, size=n_treatment_noncompliers) # Control rate\n",
    "\n",
    "    \n",
    "    # Get success of treated (compliers and noncompliers) and control\n",
    "    success_control =  max(control_outcomes.sum(),1)\n",
    "    success_treatment_compliers = max(np.sum(treatment_complier_outcomes),1)\n",
    "    success_treatment_noncompliers = max(np.sum(treatment_noncomplier_outcomes),1)\n",
    "    success_treatment = success_treatment_compliers+success_treatment_noncompliers\n",
    "\n",
    "    # Also calculcate \"failures\" as outcomes where success did not occur, used for \n",
    "    # 2x2 table\n",
    "    failure_control = N_control - success_control\n",
    "    failure_treatment_compliers = n_treatment_compliers - success_treatment_compliers\n",
    "    failure_treatment_noncompliers = n_treatment_noncompliers-success_treatment_noncompliers\n",
    "    failure_treatment = N_treatment - success_treatment\n",
    "\n",
    "    # ITT uses total treated users as the denominator \n",
    "    table = np.array([[success_treatment, success_control], [failure_treatment, failure_control]])\n",
    "    itt_oddsr, itt_p_value = fisher_exact(table, alternative='greater')\n",
    "    itt_res = (itt_p_value <= alpha)\n",
    "   \n",
    "    # CACE is just based on compliers   \n",
    "    table = np.array([[success_treatment_compliers, success_control], [failure_treatment_compliers, failure_control]])\n",
    "    cace_oddsr, cace_p_value = fisher_exact(table, alternative='greater')\n",
    "    cace_res = (cace_p_value <= alpha)\n",
    "    \n",
    "    \n",
    "    return {'itt':itt_res, 'cace':cace_res}\n",
    "\n",
    "\n",
    "def make_graph(df_results):\n",
    "    df_results['treatment_prop_label'] = df_results['treatment_prop'].apply(lambda x: f\"{x:.3f}\")\n",
    "    for dv in ['power_itt', 'power_cace']:\n",
    "        for n_days in df_results['n_days'].unique():  \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            title = \"Power Analysis Graph\\n(Days = {}, DV = {})\".format(n_days, dv)\n",
    "            plt.title(title)\n",
    "            sns.lineplot(data=df_results[df_results['n_days'] == n_days], \n",
    "                         x=\"N\", \n",
    "                         y=dv, \n",
    "                         hue=\"treatment_prop_label\")\n",
    "            plt.axhline(y=0.8, linestyle='dashed', color='red')  \n",
    "            plt.axhline(y=0.9, linestyle='dashed', color='red')  \n",
    "\n",
    "            plt.legend(title=\"Treatment Unfollow\")\n",
    "            plt.xlabel(\"Sample Size\")\n",
    "            plt.ylabel(\"Power\")\n",
    "            sns.despine()\n",
    "            plt.savefig(f\"{dv}.png\", dpi=400)\n",
    "            plt.show()\n",
    "     \n",
    "\n",
    "def find_required_N(df_results):\n",
    "    for dv in ['power_itt', 'power_cace']:\n",
    "        print(\"PRINTING RESULTS FOR MIN N AT 80% POWER FOR: {}\".format(dv))\n",
    "        df_filtered = df_results[df_results[dv] >= 0.8]\n",
    "        df_required_N = df_filtered.groupby('treatment_prop', as_index=False)['N'].min()\n",
    "        df_required_N['treatment_prop_label'] = df_required_N['treatment_prop'].apply(lambda x: f\"{x:.3f}\")\n",
    "        print(df_required_N)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"treat_status_MINIMAL_FOLLOWERS_03.04.2024__17.11.03__START0_END-1.csv\")\n",
    "\n",
    "params = {\n",
    "    'control_prop': [0.0058],\n",
    "    'treatment_prop': [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09],\n",
    "    'N_values': np.linspace(1000, 100000, 500, dtype=int),\n",
    "    'n_days':[14, 30],\n",
    "    'n_simulations': 1000,\n",
    "    \"treat_eligible\":[0.3]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "df_results = run_power_analysis(params, df)\n",
    "df_results.to_csv(\"power_analysis_results.csv\")\n",
    "make_graph(df_results)\n",
    "print(find_required_N(df_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ef3338-38d3-4f5f-a2cb-fb4f473d74df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba90d0-c080-471b-b032-b7eaeda61a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
