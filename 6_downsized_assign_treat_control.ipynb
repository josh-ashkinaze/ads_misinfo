{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65e5060c9d61342b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1: Treatment = 58772, Control = 14693\n",
      "Block 2: Treatment = 58772, Control = 14693\n",
      "Block 3: Treatment = 58772, Control = 14693\n",
      "Block 4: Treatment = 58772, Control = 14693\n",
      "Block 5: Treatment = 58772, Control = 14693\n",
      "CHECK: Passed automated tests to make sure math works out\n",
      "Adjusted Total Participants: 367325\n",
      "=========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kj/8p_kqzx533b8vldhm5sdjfc00000gn/T/ipykernel_10957/3453039304.py:69: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby('main').apply(sample_group).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK: New dataframe is expected length\n",
      "=========================\n",
      "PRINTING STATS\n",
      "Total N edges: 367325\n",
      "Followers by spreader:\n",
      "            main  Unnamed: 0  followers_id  group  treated\n",
      "0   JackPosobiec       73465         73465  73465    73465\n",
      "1   RealCandaceO       73465         73465  73465    73465\n",
      "2  charliekirk11       73465         73465  73465    73465\n",
      "3  gatewaypundit       73465         73465  73465    73465\n",
      "4       stkirsch       73465         73465  73465    73465\n",
      "=========================\n",
      "Verify logic works again:\n",
      "main           group    \n",
      "JackPosobiec   treatment    0.8\n",
      "               control      0.2\n",
      "RealCandaceO   treatment    0.8\n",
      "               control      0.2\n",
      "charliekirk11  treatment    0.8\n",
      "               control      0.2\n",
      "gatewaypundit  treatment    0.8\n",
      "               control      0.2\n",
      "stkirsch       treatment    0.8\n",
      "               control      0.2\n",
      "Name: proportion, dtype: float64\n",
      "=========================\n",
      "\n",
      "View raw counts\n",
      "main           group    \n",
      "JackPosobiec   treatment    58772\n",
      "               control      14693\n",
      "RealCandaceO   treatment    58772\n",
      "               control      14693\n",
      "charliekirk11  treatment    58772\n",
      "               control      14693\n",
      "gatewaypundit  treatment    58772\n",
      "               control      14693\n",
      "stkirsch       treatment    58772\n",
      "               control      14693\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author: Joshua Ashkinaze\n",
    "\n",
    "Description: Downsample treatment and control users based on power analysis; we do not need ALL followers.\n",
    "\n",
    "Date: 2024-04-15 17:08:50\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def make_group_files(tdf):\n",
    "    spreaders = list(tdf['main'].unique())\n",
    "    for spreader in spreaders:\n",
    "        spreader_df = tdf[tdf['main'] == spreader]\n",
    "        spreader_treat = spreader_df.query(\"treated==1\")\n",
    "        spreader_ctrl = spreader_df.query(\"treated==0\")\n",
    "        spreader_treat[['followers_id']].to_csv(f\"final_treat_twit_{spreader.lower()}.txt\", index=False, header=None)\n",
    "        spreader_ctrl[['followers_id']].to_csv(f\"final_ctrl_twit_{spreader.lower()}.txt\", index=False, header=None)\n",
    "        \n",
    "def print_stats(df):\n",
    "    print(\"PRINTING STATS\")\n",
    "    print(\"Total N edges:\", len(df))\n",
    "    print(\"Followers by spreader:\")\n",
    "    print(df.groupby(by=['main']).count().reset_index().sort_values(by=['followers_id']))\n",
    "    \n",
    "\n",
    "def assign_participants(total_n, n_blocks):\n",
    "    # Round total_n up to the nearest multiple of 25\n",
    "    # Logic for 25 is this:\n",
    "    # 1. Needs to be divisible by 5 initially since 5 spreaders\n",
    "    # 2. Then we have 80% treatment, meaning 4:1 ratio of treat:ctrl --> \n",
    "    #    so need to be able to divide through by 5 a 2nd time. \n",
    "    new_n = math.ceil(total_n / 25) * 25\n",
    "    \n",
    "    # Calculate the number of participants per block\n",
    "    participants_per_block = new_n // n_blocks\n",
    "\n",
    "    treat_per_block = int(participants_per_block * 0.8) # 80% treatment\n",
    "    ctrl_per_block = participants_per_block - treat_per_block  # 20% control\n",
    "\n",
    "    assignments = [(block, treat_per_block, ctrl_per_block) for block in range(1, n_blocks + 1)]\n",
    "    for block, treat, ctrl in assignments:\n",
    "        print(f\"Block {block}: Treatment = {treat}, Control = {ctrl}\")\n",
    "\n",
    "\n",
    "    # AUTOMATED TESTS TO MAKE SURE MATH WORKS\n",
    "    assert new_n == (treat_per_block+ctrl_per_block)*5, f\"Failed test: Total N is {n_blocks} times treat and ctrl\"\n",
    "    assert new_n >= total_n, \"Failed test: New N >= original N\"\n",
    "    assert treat_per_block/(ctrl_per_block+treat_per_block) == 0.8, \"Failed test: treat not 80%\"\n",
    "    print(\"CHECK: Passed automated tests to make sure math works out\")\n",
    "    return {'new_n': new_n, 'ctrl': ctrl_per_block, 'treat':treat_per_block}\n",
    "\n",
    "\n",
    "def downsample_df(df, n_treat, n_control):\n",
    "    def sample_group(group):\n",
    "        treated_group = group[group['treated'] == 1]\n",
    "        control_group = group[group['treated'] == 0]\n",
    "        treated_sample = treated_group.sample(n=n_treat, replace=False, random_state=42)\n",
    "        control_sample = control_group.sample(n=n_control, replace=False, random_state=42)\n",
    "\n",
    "        return pd.concat([treated_sample, control_sample])\n",
    "\n",
    "    sampled_df = df.groupby('main').apply(sample_group).reset_index(drop=True)\n",
    "\n",
    "    return sampled_df\n",
    "\n",
    "\n",
    "TOTAL_N = 367301\n",
    "\n",
    "df = pd.read_csv(\"treat_status_MINIMAL_FOLLOWERS_03.04.2024__17.11.03__START0_END-1.csv\", dtype={'followers_id':'object'})\n",
    "\n",
    "################################\n",
    "# Get the new `n` to use \n",
    "################################\n",
    "results = assign_participants(total_n=TOTAL_N, n_blocks=5)\n",
    "print(f\"Adjusted Total Participants: {results['new_n']}\")\n",
    "\n",
    "################################\n",
    "# Downsample to the new n\n",
    "################################\n",
    "print(\"=====\"*5)\n",
    "new_df = downsample_df(df, n_treat=results['treat'], n_control=results['ctrl'])\n",
    "assert len(new_df) == results['new_n'], \"Error: New dataframe is not expected length\"\n",
    "print(\"CHECK: New dataframe is expected length\")\n",
    "\n",
    "################################\n",
    "# Print some stats about new df\n",
    "################################\n",
    "print(\"=====\"*5)\n",
    "print_stats(new_df)\n",
    "print(\"=====\"*5)\n",
    "\n",
    "################################\n",
    "# Double check this logic again\n",
    "################################\n",
    "print(\"Verify logic works again:\")\n",
    "print(new_df.groupby(by=['main'])['group'].value_counts(normalize=True))\n",
    "print(\"=====\"*5)\n",
    "print(\"\\nView raw counts\")\n",
    "print(new_df.groupby(by=['main'])['group'].value_counts(normalize=False))\n",
    "\n",
    "################################\n",
    "# Make needed files\n",
    "################################\n",
    "make_group_files(new_df)\n",
    "new_df.to_csv(\"final_treat_status_MINIMAL_FOLLOWERS_03.04.2024__17.11.03__START0_END-1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
